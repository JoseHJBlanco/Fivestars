{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic ETL\n",
    "---\n",
    "\n",
    "### Goal\n",
    "Consolidate the data from the two `json` files into a single more manageable storage type, remove unnecessary data and condition columns. \n",
    "\n",
    "### Table of contents\n",
    "\n",
    "- [Imports and setup](#setup)\n",
    "- [Metadata](#meta)\n",
    "    - [Reading in JSON file](#meta_json)\n",
    "    - [Sorting out categories](#categories)\n",
    "- [Reviews](#reviews)\n",
    "    - [Reading in JSON file](#reviews_json)\n",
    "    - [Processing the \"helpful\" column](#helpful)\n",
    "- [Final data frame](#final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup <a name='setup'></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads modified libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# allows plots to be displayed inline\n",
    "%matplotlib inline\n",
    "\n",
    "# sharper figure for retina displays\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library\n",
    "import html\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# third parties\n",
    "import pandas as pd\n",
    "import pyspark as ps\n",
    "\n",
    "from pprint import pprint\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql import functions as psf\n",
    "from pyspark.sql.functions import udf, pandas_udf\n",
    "from pyspark.sql.types import MapType, StringType, IntegerType, DataType, StructType, StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spark session\n",
    "spark = ps.sql.SparkSession.builder\\\n",
    "                            .master('local[6]')\\\n",
    "                            .appName('json_etl')\\\n",
    "                            .config('spark.driver.memory', '8g')\\\n",
    "                            .config('spark.driver.maxResultSize', '32g')\\\n",
    "                            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata <a name='meta'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in `.json` file <a name='meta_json'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the metadata's schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the metadata into a \n",
    "meta = spark.read.json('../data/metadata.json.gz').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_corrupt_record',\n",
       " 'asin',\n",
       " 'brand',\n",
       " 'categories',\n",
       " 'description',\n",
       " 'imUrl',\n",
       " 'price',\n",
       " 'related',\n",
       " 'salesRank',\n",
       " 'title']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I want to drop the corrupt records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.filter(meta['_corrupt_record'].isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- imUrl: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- related: struct (nullable = true)\n",
      " |    |-- also_bought: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- also_viewed: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- bought_together: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- buy_after_viewing: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- salesRank: struct (nullable = true)\n",
      " |    |-- Appliances: long (nullable = true)\n",
      " |    |-- Arts, Crafts & Sewing: long (nullable = true)\n",
      " |    |-- Automotive: long (nullable = true)\n",
      " |    |-- Baby: long (nullable = true)\n",
      " |    |-- Beauty: long (nullable = true)\n",
      " |    |-- Books: long (nullable = true)\n",
      " |    |-- Camera &amp; Photo: long (nullable = true)\n",
      " |    |-- Cell Phones & Accessories: long (nullable = true)\n",
      " |    |-- Clothing: long (nullable = true)\n",
      " |    |-- Computers & Accessories: long (nullable = true)\n",
      " |    |-- Electronics: long (nullable = true)\n",
      " |    |-- Gift Cards Store: long (nullable = true)\n",
      " |    |-- Grocery & Gourmet Food: long (nullable = true)\n",
      " |    |-- Health & Personal Care: long (nullable = true)\n",
      " |    |-- Home &amp; Kitchen: long (nullable = true)\n",
      " |    |-- Home Improvement: long (nullable = true)\n",
      " |    |-- Industrial & Scientific: long (nullable = true)\n",
      " |    |-- Jewelry: long (nullable = true)\n",
      " |    |-- Kitchen & Dining: long (nullable = true)\n",
      " |    |-- Magazines: long (nullable = true)\n",
      " |    |-- Movies & TV: long (nullable = true)\n",
      " |    |-- Music: long (nullable = true)\n",
      " |    |-- Musical Instruments: long (nullable = true)\n",
      " |    |-- Office Products: long (nullable = true)\n",
      " |    |-- Patio, Lawn & Garden: long (nullable = true)\n",
      " |    |-- Pet Supplies: long (nullable = true)\n",
      " |    |-- Prime Pantry: long (nullable = true)\n",
      " |    |-- Shoes: long (nullable = true)\n",
      " |    |-- Software: long (nullable = true)\n",
      " |    |-- Sports &amp; Outdoors: long (nullable = true)\n",
      " |    |-- Toys & Games: long (nullable = true)\n",
      " |    |-- Video Games: long (nullable = true)\n",
      " |    |-- Watches: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to do is to convert the zipped `json` file into something with better IO speed. A `parquet` format might be a good option, but we can see that under the sales rank field there a few illegal characters. This could be solved manually, but why not create an over engineered solution for a simple problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new schema for the sales rank structure\n",
    "pattern = re.compile(r' & |, ')\n",
    "schema_str = meta.select('salesRank').schema.simpleString()\n",
    "schema_str = re.findall('struct<salesRank:(.*)>', schema_str)[0]\n",
    "new_schema = re.sub(pattern, '_', html.unescape(schema_str)).replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace white spaces, & and commas with underscores\n",
    "meta = meta.withColumn('salesRank', meta['salesRank'].cast(new_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- salesRank: struct (nullable = true)\n",
      " |    |-- Appliances: long (nullable = true)\n",
      " |    |-- Arts_Crafts_Sewing: long (nullable = true)\n",
      " |    |-- Automotive: long (nullable = true)\n",
      " |    |-- Baby: long (nullable = true)\n",
      " |    |-- Beauty: long (nullable = true)\n",
      " |    |-- Books: long (nullable = true)\n",
      " |    |-- Camera_Photo: long (nullable = true)\n",
      " |    |-- Cell_Phones_Accessories: long (nullable = true)\n",
      " |    |-- Clothing: long (nullable = true)\n",
      " |    |-- Computers_Accessories: long (nullable = true)\n",
      " |    |-- Electronics: long (nullable = true)\n",
      " |    |-- Gift_Cards_Store: long (nullable = true)\n",
      " |    |-- Grocery_Gourmet_Food: long (nullable = true)\n",
      " |    |-- Health_Personal_Care: long (nullable = true)\n",
      " |    |-- Home_Kitchen: long (nullable = true)\n",
      " |    |-- Home_Improvement: long (nullable = true)\n",
      " |    |-- Industrial_Scientific: long (nullable = true)\n",
      " |    |-- Jewelry: long (nullable = true)\n",
      " |    |-- Kitchen_Dining: long (nullable = true)\n",
      " |    |-- Magazines: long (nullable = true)\n",
      " |    |-- Movies_TV: long (nullable = true)\n",
      " |    |-- Music: long (nullable = true)\n",
      " |    |-- Musical_Instruments: long (nullable = true)\n",
      " |    |-- Office_Products: long (nullable = true)\n",
      " |    |-- Patio_Lawn_Garden: long (nullable = true)\n",
      " |    |-- Pet_Supplies: long (nullable = true)\n",
      " |    |-- Prime_Pantry: long (nullable = true)\n",
      " |    |-- Shoes: long (nullable = true)\n",
      " |    |-- Software: long (nullable = true)\n",
      " |    |-- Sports_Outdoors: long (nullable = true)\n",
      " |    |-- Toys_Games: long (nullable = true)\n",
      " |    |-- Video_Games: long (nullable = true)\n",
      " |    |-- Watches: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta.select('salesRank').printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories' names got a bit more confusing, but now we will not run into problems when trying to convert the data frame to parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.write.save('../data/metadata.parquet', format='parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = spark.read.parquet('../data/metadata.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting out categories <a name='categories'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the categories? How many are available? What do they look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          categories|\n",
      "+--------------------+\n",
      "|           [[Books]]|\n",
      "|[[Movies & TV, Mo...|\n",
      "|[[Clothing, Shoes...|\n",
      "|[[Sports & Outdoo...|\n",
      "|[[Sports & Outdoo...|\n",
      "|[[Sports & Outdoo...|\n",
      "|[[Movies & TV, Mo...|\n",
      "|           [[Books]]|\n",
      "|[[Sports & Outdoo...|\n",
      "|           [[Books]]|\n",
      "|           [[Books]]|\n",
      "|           [[Books]]|\n",
      "|           [[Books]]|\n",
      "|           [[Books]]|\n",
      "|           [[Books]]|\n",
      "|           [[Books]]|\n",
      "|           [[Books]]|\n",
      "|           [[Books]]|\n",
      "|[[Sports & Outdoo...|\n",
      "|           [[Books]]|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta.select('categories').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories seem to be strings separated by commas stored inside embedded lists. Let's try to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| categories_exploded|\n",
      "+--------------------+\n",
      "|             [Books]|\n",
      "|[Movies & TV, Mov...|\n",
      "|[Clothing, Shoes ...|\n",
      "|[Clothing, Shoes ...|\n",
      "|[Sports & Outdoor...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = psf.explode(meta['categories'])\n",
    "exploded_meta = meta.withColumn('categories_exploded', categories)\n",
    "exploded_meta.select('categories_exploded').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to go deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_corrupt_record',\n",
       " 'asin',\n",
       " 'brand',\n",
       " 'categories',\n",
       " 'description',\n",
       " 'imUrl',\n",
       " 'price',\n",
       " 'related',\n",
       " 'salesRank',\n",
       " 'title',\n",
       " 'categories_exploded']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| categories_exploded|\n",
      "+--------------------+\n",
      "|               Books|\n",
      "|         Movies & TV|\n",
      "|              Movies|\n",
      "|Clothing, Shoes &...|\n",
      "|               Girls|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = psf.explode(exploded_meta['categories_exploded'])\n",
    "exploded_meta = exploded_meta.withColumn('categories_exploded', categories)\n",
    "exploded_meta.select('categories_exploded').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! Now is only a matter of splitting the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|       category|\n",
      "+---------------+\n",
      "|          Books|\n",
      "|    Movies & TV|\n",
      "|         Movies|\n",
      "|       Clothing|\n",
      "|Shoes & Jewelry|\n",
      "+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = psf.explode(exploded_meta['categories_exploded'])\n",
    "exploded_meta = exploded_meta.withColumn('category', psf.explode(psf.split('categories_exploded', ', ')))\n",
    "exploded_meta.select('category').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            category|\n",
      "+--------------------+\n",
      "|    Personal Finance|\n",
      "|    Stress Reduction|\n",
      "|      Micro SD Cards|\n",
      "|      Pegged Puzzles|\n",
      "|         Note Taking|\n",
      "|Hand & Arm Protec...|\n",
      "|                Goth|\n",
      "|    Ballets & Dances|\n",
      "|            Ska Punk|\n",
      "|        Bread Knives|\n",
      "|  Skullies & Beanies|\n",
      "|Bathroom Accessories|\n",
      "|         Knife Cases|\n",
      "|      Serving Dishes|\n",
      "|           Envelopes|\n",
      "|              Easter|\n",
      "|             Septets|\n",
      "|            Ranchera|\n",
      "|Portable & Novelt...|\n",
      "|          Aida Cloth|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_meta.select('category').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18360"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_meta.select('category').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... using 18k categories doesn't sound very promising..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_meta.unpersist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look a `salesRank` instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesrank_samples = meta.select('salesRank').take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesrank_dicts = [sample['salesRank'].asDict() for sample in salesrank_samples if sample['salesRank']]\n",
    "salesrank_df = pd.DataFrame(salesrank_dicts)\n",
    "# count the number of non null values in each row\n",
    "salesrank_df.count(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like each `salesRank` contains only one not null value, but just to be sure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def cat_counts(struct):\n",
    "    '''\n",
    "    Simple function used to could the number or non null values\n",
    "    in each `salesRank` field.\n",
    "    '''\n",
    "    if struct:\n",
    "        struct_values = struct.asDict().values()\n",
    "        cats = 0\n",
    "        for value in struct_values:\n",
    "            if value:\n",
    "                cats += 1\n",
    "        return cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|n_cats|  count|\n",
      "+------+-------+\n",
      "|     0|  23623|\n",
      "|  null|2228167|\n",
      "|     1|6151598|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta.select(cat_counts('salesRank').alias('n_cats')).groupby('n_cats').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, each observation has at most one category. Good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct categories: 33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Appliances',\n",
       " 'Arts_Crafts_Sewing',\n",
       " 'Automotive',\n",
       " 'Baby',\n",
       " 'Beauty',\n",
       " 'Books',\n",
       " 'Camera_Photo',\n",
       " 'Cell_Phones_Accessories',\n",
       " 'Clothing',\n",
       " 'Computers_Accessories',\n",
       " 'Electronics',\n",
       " 'Gift_Cards_Store',\n",
       " 'Grocery_Gourmet_Food',\n",
       " 'Health_Personal_Care',\n",
       " 'Home_Kitchen',\n",
       " 'Home_Improvement',\n",
       " 'Industrial_Scientific',\n",
       " 'Jewelry',\n",
       " 'Kitchen_Dining',\n",
       " 'Magazines',\n",
       " 'Movies_TV',\n",
       " 'Music',\n",
       " 'Musical_Instruments',\n",
       " 'Office_Products',\n",
       " 'Patio_Lawn_Garden',\n",
       " 'Pet_Supplies',\n",
       " 'Prime_Pantry',\n",
       " 'Shoes',\n",
       " 'Software',\n",
       " 'Sports_Outdoors',\n",
       " 'Toys_Games',\n",
       " 'Video_Games',\n",
       " 'Watches']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_sample = meta.select('salesRank').take(1)[0]\n",
    "cats = struct_sample['salesRank'].__fields__\n",
    "print(f'Number of distinct categories: {len(cats)}')\n",
    "cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aahhh, much more manageable. From now on, this will be our categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('category', StringType()),\n",
    "    StructField('rank', IntegerType())\n",
    "])\n",
    "\n",
    "@udf(schema)\n",
    "def get_catrank(struct):\n",
    "    '''\n",
    "    Returns the category with non null value if it exists.\n",
    "    '''\n",
    "    if struct:\n",
    "        struct_items = list(struct.asDict().items())\n",
    "        for cat, rank in struct_items:\n",
    "            if rank:\n",
    "                cat_field = StructField('category', StringType(), )\n",
    "                return {'category': cat, 'rank': rank}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_corrupt_record',\n",
       " 'asin',\n",
       " 'brand',\n",
       " 'categories',\n",
       " 'description',\n",
       " 'imUrl',\n",
       " 'price',\n",
       " 'related',\n",
       " 'salesRank',\n",
       " 'title',\n",
       " 'category',\n",
       " 'sales_rank']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_ranks = get_catrank(meta['salesRank'])\n",
    "category = cat_ranks.getField('category').alias('category')\n",
    "sales_rank = cat_ranks.getField('rank').alias('sales_rank')\n",
    "\n",
    "meta = meta.withColumn('category', category)\n",
    "meta = meta.withColumn('sales_rank', sales_rank)\n",
    "meta.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it would be a good idea to remove unnecessary columns such as `imUrl` and `brand`. I will leave in `price` just out of curiosity and `asin` is necessary to join this data frame with the reviews one latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = {\n",
    "    'asin',\n",
    "    'category',\n",
    "    'price',\n",
    "    'sales_rank'\n",
    "}\n",
    "\n",
    "meta = meta.select(*keep_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.write.parquet('../data/metadata_clean.parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews <a name='reviews'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in `.json` file <a name='reviews_json'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = spark.read.json('../data/amazon_reviews.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have `unixReviewTime` so the `reviewTime` column is redundant. We also don't care about the `reviewerID` or `reviewerName`, so they can be dropped as well, but before dropping `reviewerID`, I will create a unique ID for each review composed by the `asin` and the `reviewerID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                  id|\n",
      "+--------------------+\n",
      "|0000013714_ACNGUP...|\n",
      "|0000013714_A2SUAM...|\n",
      "|0000013714_APOZ15...|\n",
      "|0000013714_AYEDW3...|\n",
      "|0000013714_A1KLCG...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_id = psf.concat_ws('_', 'asin', 'reviewerID')\n",
    "reviews = reviews.withColumn('id', review_id)\n",
    "reviews.select('id').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop('reviewTime', 'reviewerName', 'reviewerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+--------------------+--------------------+--------------+--------------------+\n",
      "|      asin|helpful|overall|          reviewText|             summary|unixReviewTime|                  id|\n",
      "+----------+-------+-------+--------------------+--------------------+--------------+--------------------+\n",
      "|0000013714| [0, 0]|    4.0|We use this type ...|         Nice Hymnal|    1386028800|0000013714_ACNGUP...|\n",
      "|0000013714| [2, 3]|    5.0|I bought this for...|Heavenly Highway ...|    1252800000|0000013714_A2SUAM...|\n",
      "|0000013714| [0, 0]|    5.0|This is a large s...|   Awesome Hymn Book|    1362787200|0000013714_APOZ15...|\n",
      "+----------+-------+-------+--------------------+--------------------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the `helpful` column <a name='helpful'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the helpful column is populated by arrays of length 2, where the first element corresponds to the number of positive votes given to the review and while the second element represents the total number of votes (positive + negative). In order to make the data more easily accessible, it is a good idea to extract to explode the array and create two columns out of it, `positiveVotes` and `totalVotes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+--------------------+--------------------+--------------+--------------------+-------------+----------+\n",
      "|      asin|helpful|overall|          reviewText|             summary|unixReviewTime|                  id|positiveVotes|totalVotes|\n",
      "+----------+-------+-------+--------------------+--------------------+--------------+--------------------+-------------+----------+\n",
      "|0000013714| [0, 0]|    4.0|We use this type ...|         Nice Hymnal|    1386028800|0000013714_ACNGUP...|            0|         0|\n",
      "|0000013714| [2, 3]|    5.0|I bought this for...|Heavenly Highway ...|    1252800000|0000013714_A2SUAM...|            2|         3|\n",
      "|0000013714| [0, 0]|    5.0|This is a large s...|   Awesome Hymn Book|    1362787200|0000013714_APOZ15...|            0|         0|\n",
      "|0000013714| [0, 0]|    5.0|We use this hymn ...|Hand Clapping Toe...|    1325462400|0000013714_AYEDW3...|            0|         0|\n",
      "|0000013714| [0, 0]|    3.0|One review advise...|          Misleading|    1376092800|0000013714_A1KLCG...|            0|         0|\n",
      "+----------+-------+-------+--------------------+--------------------+--------------+--------------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "positive_votes = reviews['helpful'].getItem(0)\n",
    "total_votes = reviews['helpful'].getItem(1)\n",
    "\n",
    "reviews = reviews.withColumn('positiveVotes', positive_votes)\n",
    "reviews = reviews.withColumn('totalVotes', total_votes)\n",
    "\n",
    "reviews.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now we can drop the `helpful` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop('helpful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing that I would like to check is whether or not `overall` contains \"half-stars\". If not, it makes more sense to store the values as integers instead of doubles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|overall|\n",
      "+-------+\n",
      "|    1.0|\n",
      "|    4.0|\n",
      "|    3.0|\n",
      "|    2.0|\n",
      "|    5.0|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.select('overall').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integers it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_overall = reviews['overall'].cast('integer')\n",
    "reviews = reviews.withColumn('overall', integer_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final `reviews` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------------+--------------+--------------------+-------------+----------+\n",
      "|      asin|overall|          reviewText|             summary|unixReviewTime|                  id|positiveVotes|totalVotes|\n",
      "+----------+-------+--------------------+--------------------+--------------+--------------------+-------------+----------+\n",
      "|0000013714|      4|We use this type ...|         Nice Hymnal|    1386028800|0000013714_ACNGUP...|            0|         0|\n",
      "|0000013714|      5|I bought this for...|Heavenly Highway ...|    1252800000|0000013714_A2SUAM...|            2|         3|\n",
      "|0000013714|      5|This is a large s...|   Awesome Hymn Book|    1362787200|0000013714_APOZ15...|            0|         0|\n",
      "|0000013714|      5|We use this hymn ...|Hand Clapping Toe...|    1325462400|0000013714_AYEDW3...|            0|         0|\n",
      "|0000013714|      3|One review advise...|          Misleading|    1376092800|0000013714_A1KLCG...|            0|         0|\n",
      "|0000029831|      4|This work bears d...|Logical follow-up...|    1393286400|0000029831_A14A5Q...|            3|         3|\n",
      "|0000029831|      5|You may laugh, bu...|The superior clea...|    1393200000|0000029831_A3W2PX...|            4|         4|\n",
      "|0000029831|      5|Do not try and va...|Very deep and tho...|    1393286400|0000029831_A2GKR2...|            3|         3|\n",
      "|0000029831|      5|What if Dread had...|        WHAT IF....?|    1393200000|0000029831_A1MC4E...|            3|         3|\n",
      "|0000029831|      5|I thought this bo...|              Review|    1393200000|0000029831_A23PIS...|            5|         5|\n",
      "|0000031887|      4|This was a really...|Really Cute but r...|    1337990400|0000031887_A2G0LN...|            1|         1|\n",
      "|0000031887|      2|the tutu color wa...|not very good mat...|    1361059200|0000031887_A2R3K1...|            1|         1|\n",
      "|0000031887|      4|Bought it for my ...|           i love it|    1390435200|0000031887_A1P0IH...|            0|         0|\n",
      "|0000031887|      5|This is a great t...|Great tutu-  not ...|    1297468800|0000031887_A1KLRM...|            0|         0|\n",
      "|0000031887|      5|Got this for our ...|                Tutu|    1356480000|0000031887_A1GQPA...|            0|         0|\n",
      "|0000031887|      5|I bought this for...|         Very Cute!!|    1358553600|0000031887_A2G5TC...|            0|         0|\n",
      "|0000031887|      5|Just as described...|          Fantastic!|    1371859200|0000031887_AEAN37...|            0|         0|\n",
      "|0000031887|      5|Purchased it for ...|My daughter loved...|    1402876800|0000031887_A1MCJO...|            0|         0|\n",
      "|0000031887|      4|Very cute, shorte...|        Good product|    1386633600|0000031887_A2PSIV...|            0|         0|\n",
      "|0000031887|      5|Vey cute and perf...|                cute|    1392681600|0000031887_A3CHBY...|            0|         0|\n",
      "+----------+-------+--------------------+--------------------+--------------+--------------------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.write.parquet('../data/reviews_clean.parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to join the two data frames into one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final data frame <a name='final'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = spark.read.parquet('../data/metadata_clean.parquet')\n",
    "reviews = spark.read.parquet('../data/reviews_clean.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = reviews.join(meta, on='asin', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving the processed data frame, let's change the column names so to more \"pythonic\" strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_cols = [\n",
    "    'asin',\n",
    "    'rating',\n",
    "    'review',\n",
    "    'summary',\n",
    "    'review_time',\n",
    "    'id',\n",
    "    'pos_votes',\n",
    "    'total_votes',\n",
    "    'sales_rank',\n",
    "    'category',\n",
    "    'price'\n",
    "]\n",
    "\n",
    "final_df = final_df.toDF(*renamed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.unpersist()\n",
    "reviews.unpersist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving the final version, I would like to change the column names to something a bit more pythonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.write.parquet('../data/amazon.parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = spark.read.parquet('../data/amazon.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+-----------+---------+-----------+----------+--------+-----+\n",
      "|rating|              review|             summary|review_time|pos_votes|total_votes|sales_rank|category|price|\n",
      "+------+--------------------+--------------------+-----------+---------+-----------+----------+--------+-----+\n",
      "|     5|This book hits th...|        An easy read| 1383091200|        0|          0|   1127575|   Books| 6.64|\n",
      "|     4|Very good book de...|Interesting pictu...| 1352592000|        0|          0|   1127575|   Books| 6.64|\n",
      "|     4|Some of Agatha Ch...|An engaging memoi...| 1282608000|        4|          4|   1127575|   Books| 6.64|\n",
      "|     5|This inspiring au...|An Autobiography,...| 1390780800|        0|          0|   1127575|   Books| 6.64|\n",
      "|     4|Sure reading Agat...|\"Instead  I went ...| 1312156800|        3|          4|   1127575|   Books| 6.64|\n",
      "|     4|I was a bit hesit...|Personally and cu...| 1398816000|        0|          0|   1127575|   Books| 6.64|\n",
      "|     4|There are really ...|There are really ...|  985219200|       26|         36|   1127575|   Books| 6.64|\n",
      "|     5|I picked up Agath...|enjoyable read!wh...| 1095638400|       43|         45|   1127575|   Books| 6.64|\n",
      "|     3|Interesting to re...|An unexpected lif...| 1383868800|        0|          0|   1127575|   Books| 6.64|\n",
      "|     5|I'm an avid reade...|Great life story ...| 1048982400|        4|          5|   1127575|   Books| 6.64|\n",
      "|     5|As an avid fan of...|    My Favorite Book| 1101254400|       15|         17|   1127575|   Books| 6.64|\n",
      "|     5|In reading about ...|What a lady! That...| 1285113600|        1|          1|   1127575|   Books| 6.64|\n",
      "|     5|Agatha Christie i...|Welcome to the wo...| 1228694400|        1|          1|   1127575|   Books| 6.64|\n",
      "|     5|I have read just ...|    A Very Good Read| 1369526400|        0|          0|   1127575|   Books| 6.64|\n",
      "|     5|This is a reprint...|wonderful look at...| 1321920000|        9|         10|   1127575|   Books| 6.64|\n",
      "|     5|This is a must ha...|   Loving this book.| 1359244800|        0|          1|   1127575|   Books| 6.64|\n",
      "|     5|If you're a fan o...|           Loved it!| 1388966400|        0|          0|   1127575|   Books| 6.64|\n",
      "|     5|The autobiography...|Agatha Christie: ...| 1371340800|        0|          2|   1127575|   Books| 6.64|\n",
      "|     5|I loved reading t...|She Was a Master ...| 1381968000|        0|          0|   1127575|   Books| 6.64|\n",
      "|     5|Often times autob...|One of my favorit...| 1150329600|       31|         33|   1127575|   Books| 6.64|\n",
      "+------+--------------------+--------------------+-----------+---------+-----------+----------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.drop('asin').drop('id').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful! That is it for ETL!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
